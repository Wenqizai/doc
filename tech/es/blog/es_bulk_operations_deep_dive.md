# Elasticsearch 批量操作深度解析：原理、实践与失败处理

在与 Elasticsearch 交互时，批量操作是提升性能、实现高吞吐量的关键。本文档将深入探讨几种核心的批量 API，包括它们的内部工作原理、最佳实践以及如何优雅地处理失败。

---

## 1. `_bulk` API (批量写入、更新、删除)

`_bulk` API 是 Elasticsearch 中最重要、最基础的性能优化工具，适用于任何需要大规模写入、更新或删除数据的场景。

### 原理解释

- **核心目的**: 将成百上千个独立的 `index` (创建或覆盖)、`create` (仅创建)、`update` (部分更新) 或 `delete` (删除) 操作捆绑到**单个 HTTP 请求**中。
- **工作流程**:
    1.  **客户端**: 将一个包含多个操作的请求发送到集群的任一节点（该节点成为协调节点）。请求体采用 NDJSON 格式。
    2.  **协调节点**: 解析请求，并根据文档的 `_id` 或 `_routing` 值计算出目标分片，然后将这些子操作分组。
    3.  **分发与执行**: 协调节点将分组后的操作并行地转发到持有相应主分片 (Primary Shard) 的数据节点。
    4.  **主分片与副本**: 数据节点在主分片上执行操作，成功后，再将变更并行地复制到所有副本分片 (Replica Shards)。
    5.  **结果聚合**: 所有节点将执行结果返回给协调节点，协调节点再将这些结果聚合并一次性返回给客户端。
- **关键优势**: 其高性能的根本原因是**大幅减少了网络往返 (Network Round-Trips)**。处理 1000 个文档，`_bulk` 只需要 1 次网络请求，而单独操作需要 1000 次，极大地降低了网络延迟和请求开销。

### 示例 (Example)

一个 `_bulk` 请求包含多个操作，每个操作都由 "action and metadata" 行和可选的 "source" 行组成。

```json
POST /_bulk
{ "index" : { "_index" : "my-index-000001", "_id" : "1" } }
{ "title": "第一篇文档", "status": "published" }
{ "delete" : { "_index" : "my-index-000001", "_id" : "2" } }
{ "create" : { "_index" : "my-index-000001", "_id" : "3" } }
{ "title": "第三篇文档", "status": "draft" }
{ "update" : { "_index": "my-index-000001", "_id" : "1" } }
{ "doc" : { "status" : "archived" } }
```

### 最佳实践

- **合适的批次大小**: 这至关重要，需要在性能和内存消耗之间找到平衡点。
    - **物理大小**: 一个推荐的起点是 **5-15 MB**。过小的批次（如 < 1MB）会导致网络开销占比过高；过大的批次（如 > 50MB）会在协调节点上消耗大量内存，引发 GC 压力甚至 OOM (Out Of Memory)。
    - **文档数量**: 通常在 **1,000 到 5,000 个文档**之间，具体取决于单个文档的大小。
    - **必须通过基准测试来调优**，以找到最适合你的业务负载和集群配置的最佳大小。
- **并发请求**: 为了完全压榨集群的写入能力，应该使用多个线程或客户端进行**并发的 `_bulk` 请求**。并发数通常可以设置为集群数据节点 CPU 核心数的 1 到 2 倍。
- **使用 `BulkProcessor`**: 对于 Java 等官方客户端，强烈推荐使用 `BulkProcessor`。它是一个辅助类，可以优雅地自动处理：
    - 根据文档数量、大小或时间间隔自动刷新（发送）批次。
    - 管理并发请求。
    - 内置重试策略（例如，在收到 `429 Too Many Requests` 这种可恢复的错误时自动退避重试）。
- **优化索引设置 (大数据量导入时)**:
    1.  **临时禁用副本**: `"number_of_replicas": 0` (写入只发生在主分片，减少写入放大)。
    2.  **临时禁用刷新间隔**: `"refresh_interval": "-1"` (避免产生大量小的 segment 文件)。
    3.  导入完成后，再将这些设置恢复，并可以考虑手动触发一次 `_forcemerge` 来合并段以优化后续查询性能。

### 失败处理

- **非事务性**: `_bulk` 请求本身**不是事务性的**。整个请求的成功（HTTP 200 OK）不代表内部所有子操作都成功。
- **检查响应体**: 必须检查响应体。`_bulk` 的响应中会包含一个 `items` 数组，与请求中的操作一一对应。
- **`errors` 字段**: 响应的顶层会有一个布尔值 `errors` 字段。如果为 `true`，说明至少有一个操作失败了，此时**必须遍历 `items` 数组**来定位并处理失败的子操作。
- **处理单个失败**: `items` 数组中的每个对象都包含了操作的执行结果。如果某个操作失败，其对象中会有一个 `error` 字段，包含了失败的原因（如版本冲突、解析错误等）。
- **重试策略**: 客户端代码应该实现重试逻辑，特别是对于可恢复的错误（如 `429 Too Many Requests` 或暂时的网络问题），应等待一段时间后重试失败的子操作。

---

## 2. `_mget` (Multi-Get) API (批量读取)

### 原理解释

`_mget` 用于通过文档 ID 一次性获取多个文档。其原理与 `_bulk` 类似，协调节点接收请求后，会将不同 ID 的 `get` 请求分发到持有对应分片的节点上并行执行，最后汇总结果。

### 示例 (Example)

可以在请求体中明确指定每个文档的 `_index` 和 `_id`。

```json
GET /_mget
{
  "docs": [
    {
      "_index": "my-index-000001",
      "_id": "1"
    },
    {
      "_index": "my-index-000001",
      "_id": "3"
    },
    {
      "_index": "another-index",
      "_id": "42"
    }
  ]
}
```

如果所有文档都在同一个索引中，也可以使用更简洁的语法：

```json
GET /my-index-000001/_mget
{
  "ids": ["1", "3"]
}
```

### 最佳实践

- 只要你需要根据一个 ID 列表获取多个文档，就应该使用 `_mget` 而不是在循环中发送单个 `get` 请求。
- 请求的文档不宜过多（例如超过几千个），否则响应体会非常大，消耗客户端内存和网络带宽。

### 失败处理

`_mget` 响应的 `docs` 数组与请求中的文档一一对应。整个 `_mget` 请求通常不会失败。你需要检查数组中的每个对象：
- 如果获取成功，`"found"` 字段为 `true`。
- 如果文档不存在，`"found"` 字段为 `false`。
- 如果获取某个文档时发生内部错误，该对象会包含一个 `error` 字段。

---

## 3. `_msearch` (Multi-Search) API (批量搜索)

### 原理解释

`_msearch` 允许在单个 HTTP 请求中执行多个独立的搜索查询。协调节点会解析 NDJSON 格式的请求体，将各个搜索请求分发出去（可能并行执行），然后收集所有结果并统一返回。这对于需要加载多个数据组件的仪表盘 (Dashboard) 类应用非常有用。

### 示例 (Example)

请求体由多个 header/body 对组成。如果 header 为空 (`{}`)，将使用 URL 中指定的默认索引。

```json
POST /my-index-000001/_msearch
{}
{ "query": { "match": { "status": "published" } }, "from": 0, "size": 10 }
{ "index": "another-index" }
{ "query": { "match": { "user.id": "kimchy" } } }
{}
{ "query": { "match_all": {} } }
```
上面的示例在一个请求中执行了三个搜索：
1. 在 `my-index-000001` 中搜索 `status` 为 `published` 的文档。
2. 在 `another-index` 中搜索 `user.id` 为 `kimchy` 的文档。
3. 在 `my-index-000001` (默认) 中执行 `match_all` 查询。

### 最佳实践

- 使用 NDJSON 格式，每个查询由 header 和 body 两部分组成。
- 可以在同一个 `_msearch` 请求中查询不同的索引。
- 注意，整个请求的响应时间取决于**其中最慢的那个查询**。一个耗时长的查询会拖慢整个批量请求。

### 失败处理

响应体包含一个 `responses` 数组，每个元素对应一个搜索查询的结果。如果某个查询因为语法错误等原因失败了，其对应的响应元素会包含一个 `error` 对象，但这**不会影响其他查询的成功执行**。客户端需要遍历 `responses` 数组来分别处理每个查询的结果或失败。

---

## 4. `_update_by_query` API (按查询条件批量更新)

### 原理解释

此 API 允许根据一个查询条件来更新所有匹配的文档。它从根本上避免了"`search` -> `将大量结果拉到客户端` -> `客户端循环修改` -> `_bulk` 更新"这种低效且网络开销巨大的流程。ES 内部会为匹配的文档创建一个快照 (snapshot)，然后滚动遍历所有文档并执行更新脚本，这个过程是在服务端分批、高效完成的。

### 示例 (Example)

将所有 `status` 为 `draft` 且作者为 `testuser` 的文档的状态更新为 `archived`，并增加一个 `archived_date` 字段。

```json
POST /my-index-000001/_update_by_query?conflicts=proceed
{
  "script": {
    "source": "ctx._source.status = params.new_status; ctx._source.archived_date = params.archive_date",
    "lang": "painless",
    "params": {
      "new_status": "archived",
      "archive_date": "2024-01-01T00:00:00Z"
    }
  },
  "query": {
    "bool": {
      "must": [
        { "term": { "status": "draft" } },
        { "term": { "user.id": "testuser" } }
      ]
    }
  }
}
```
- **`script`**: 定义了要执行的更新逻辑。使用 `ctx._source` 来访问文档字段，使用 `params` 来安全地传递变量。
- **`query`**: 定义了筛选要更新文档的条件。
- **`?conflicts=proceed`**: URL 参数，表示如果遇到版本冲突，则跳过该文档并继续处理下一个，而不是中止整个任务。

### 最佳实践

- **高风险操作**: 该操作会直接修改大量数据，**务必在非生产环境中充分验证其查询条件和更新脚本的正确性**。
- **异步执行**: 对于涉及大量文档的更新，这通常是一个耗时很长的任务。应该使用 `wait_for_completion=false` 参数让它在后台异步执行，然后通过 **Tasks API** (`GET /_tasks/{task_id}`) 来监控其进度。
- **并行化处理 (`slices`)**: 默认情况下，`_update_by_query` 是单线程执行的，对于大索引会非常慢。强烈建议设置 `slices` 参数（例如 `slices=auto` 或 `slices=5`）来将任务分割成多个切片并行处理，这能极大提升效率。
- **处理版本冲突**: 默认情况下，遇到版本冲突任务会中止。可以设置 `conflicts=proceed` 让任务记录冲突数量并继续执行。
- **限流**: 使用 `requests_per_second` 参数可以限制每秒处理的文档数（默认为-1，不限流），以避免操作对集群造成过大冲击。

### 失败处理

- **同步执行**: 如果同步执行（不推荐用于大数据量），响应会直接告诉你成功、失败、超时或冲突的信息。
- **异步执行**: 使用 Tasks API (`GET /_tasks/{task_id}`) 来获取任务的最终状态。任务完成后，其结果中会包含详细的成功、失败、版本冲突和超时等统计信息。客户端需要检查这些信息来确认任务是否按预期完成。如果 `failures` 数组不为空，说明在执行过程中出现了无法恢复的错误。

---

## 总结对比

| API | 用途 | 核心优势 | 失败模式 | 关键实践 |
| :--- | :--- | :--- | :--- | :--- |
| **`_bulk`** | 批量写/改/删 | 极大提升写入吞吐量 | 单个子操作可失败 | 调优批次大小和并发数，检查响应体 |
| **`_mget`** | 根据 ID 批量读 | 减少读操作的网络开销 | 单个文档可失败/未找到 | 适用于已知 ID 列表的精确获取 |
| **`_msearch`**| 批量执行多个搜索查询 | 优化复杂页面或报表的数据加载 | 单个查询可失败 | 适用于仪表盘等场景，注意慢查询 |
| **`_update_by_query`**| 按条件批量更新 | 避免客户端-服务端大数据量往返 | 任务级别失败 | 异步执行、并行化 (`slices`)、限流 |

</rewritten_file> 